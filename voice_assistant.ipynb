{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Build-A-Voice-Assistant-Using-Google-API-Key\\voice\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Set your API key\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")  # Correct usage of os.getenv\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"models/gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voice_assistant(input_user):\n",
    "    ## Improved prompt with focus on concise and direct answers\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant in an engaging conversation with a user. The user just asks the following question: '{input_user}'\n",
    "    Provide a direct and informative answer, focusing on the exact details the user is asking for. Avoid unnecessary elaboration or asking follow-up question unless essential.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = model.generate_content(prompt).text\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning is a subfield of machine learning that uses artificial neural networks with multiple layers (hence \"deep\") to analyze data.  These networks learn complex patterns and representations directly from data, often without needing explicit feature engineering.  This allows them to solve complex tasks like image recognition, natural language processing, and speech recognition.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_user = input(\"Start Conversation here:.....\")\n",
    "print(voice_assistant(input_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    }
   ],
   "source": [
    "print(\"The End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
